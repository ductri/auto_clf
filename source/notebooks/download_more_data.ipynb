{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import json\n",
    "\n",
    "from naruto_skills import solr\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_topics = ['6732', '4084', '2638', '3245', '23709', '23708', '7798', '40266', '35786']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:List topics: ['6732', '4084', '2638', '3245', '23709', '23708', '7798', '40266', '35786']\n"
     ]
    }
   ],
   "source": [
    "logging.info('List topics: %s', list_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = list(set([98985,98985,98985,98985,123638,123638,98985,123638,123638]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloading 1/9 which is 6732\n",
      "INFO:root:Crawled topic 6732 on page 1, 515/515 done\n",
      "INFO:root:Crawled topic 6732 on page 2, 515/515 done\n",
      "INFO:root:Topic: 6732 - No rows: 515\n",
      "INFO:root:Downloading 2/9 which is 4084\n",
      "INFO:root:Crawled topic 4084 on page 1, 614/614 done\n",
      "INFO:root:Crawled topic 4084 on page 2, 614/614 done\n",
      "INFO:root:Topic: 4084 - No rows: 1129\n",
      "INFO:root:Downloading 3/9 which is 2638\n",
      "INFO:root:Crawled topic 2638 on page 1, 1078/1078 done\n",
      "INFO:root:Crawled topic 2638 on page 2, 1078/1078 done\n",
      "INFO:root:Topic: 2638 - No rows: 2207\n",
      "INFO:root:Downloading 4/9 which is 3245\n",
      "INFO:root:Crawled topic 3245 on page 1, 1668/1668 done\n",
      "INFO:root:Crawled topic 3245 on page 2, 1668/1668 done\n",
      "INFO:root:Topic: 3245 - No rows: 3875\n",
      "INFO:root:Downloading 5/9 which is 23709\n",
      "INFO:root:Crawled topic 23709 on page 1, 364/364 done\n",
      "INFO:root:Crawled topic 23709 on page 2, 364/364 done\n",
      "INFO:root:Topic: 23709 - No rows: 4239\n",
      "INFO:root:Downloading 6/9 which is 23708\n",
      "INFO:root:Crawled topic 23708 on page 1, 565/565 done\n",
      "INFO:root:Crawled topic 23708 on page 2, 565/565 done\n",
      "INFO:root:Topic: 23708 - No rows: 4804\n",
      "INFO:root:Downloading 7/9 which is 7798\n",
      "INFO:root:Crawled topic 7798 on page 1, 0/0 done\n",
      "INFO:root:Topic: 7798 - No rows: 4804\n",
      "INFO:root:Downloading 8/9 which is 40266\n",
      "ERROR:root:Error: 'response'\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-6-d61ee86797a4>\", line 24, in <module>\n",
      "    limit=int(5e4), batch_size=int(4e3+1), username='trind', password='Jhjhsdf$3&sdsd')\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/naruto_skills/solr.py\", line 74, in crawl_topic\n",
      "    min(pos + n_rows, result['response']['numFound']),\n",
      "KeyError: 'response'\n",
      "INFO:root:Downloading 9/9 which is 35786\n",
      "INFO:root:Crawled topic 35786 on page 1, 5/5 done\n",
      "INFO:root:Crawled topic 35786 on page 2, 5/5 done\n",
      "INFO:root:Topic: 35786 - No rows: 4809\n"
     ]
    }
   ],
   "source": [
    "assert len(list_topics) == len(set(list_topics))\n",
    "start = '2019-01-01T00:00:00'\n",
    "end = '2019-05-01T00:00:00'\n",
    "filters = (\n",
    "    'q=*:*',\n",
    "    'fq=-is_ignore:1',\n",
    "    'fq=-is_noisy:1',\n",
    "    'fq=is_approved:1',\n",
    "    'wt=json',\n",
    "    'fq=copied_at:[%sZ TO %sZ]' % (start, end),\n",
    "    'fq=search_text:*',\n",
    "    'fq=sentiment:*',\n",
    "    'fq=tags:(%s)' % (' '.join([str(item) for item in tags]))\n",
    ")\n",
    "fields = ('id', 'copied_at', 'search_text', 'sentiment', 'sentiment_auto', 'tags', 'link', 'platform',\n",
    "          'id_reference', 'created_date', 'mention_type', 'id_source', 'source_type')\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for idx, topic in enumerate(list_topics):\n",
    "    logging.info('Downloading %s/%s which is %s', idx + 1, len(list_topics), topic)\n",
    "    try:\n",
    "        df_tmp = solr.crawl_topic(domain='http://solrtopic.younetmedia.com', topic=topic, filters=filters,\n",
    "                              fields=fields,\n",
    "                              limit=int(5e4), batch_size=int(4e3+1), username='trind', password='Jhjhsdf$3&sdsd')\n",
    "\n",
    "        df = df.append(df_tmp)\n",
    "        logging.info('Topic: %s - No rows: %s', topic, df.shape[0])\n",
    "    except KeyError as e:\n",
    "        logging.exception('Error: %s', e)\n",
    "        continue\n",
    "    except json.decoder.JSONDecodeError as e:\n",
    "        logging.exception('Error: %s', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4809, 14)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=['id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True, subset=['search_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4663, 14)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mention'] = df['search_text'].map(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['mention'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4663, 15)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/source/main/data_download/output/positive_class_11.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_tags = pd.read_csv('/source/main/data_download/output/auxiliary/app_tags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_tags[df_tags['id']==87294]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_tags.dropna(subset=['id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_tags = df_tags[df_tags['type']=='ATTRIBUTE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_tags = df_tags[df_tags['name'].map(lambda x: x.lower().find('taste') != -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_tags.dropna(inplace=True, subset=['id_sentiment_domain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_tags = df_tags[df_tags['id_sentiment_domain'].map(lambda x: x.lower()=='milk' or x.lower()=='coffee_drink')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pos = set(df_tags[df_tags['name'].map(lambda x: x.lower().find('positive') != -1)]['id'])\n",
    "neutral = set(df_tags[df_tags['name'].map(lambda x: x.lower().find('neutral') != -1)]['id'])\n",
    "neg = set(df_tags[df_tags['name'].map(lambda x: x.lower().find('negative') != -1)]['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pos[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "neg[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "list(set(df_tags['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
