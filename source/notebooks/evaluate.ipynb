{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/source/main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import time\n",
    "from itertools import chain\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from naruto_skills.new_voc import Voc\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model_def.siamese_model_8 import SiameseModel\n",
    "from model_def.siamese_core import SiameseModelCore\n",
    "from utils import pytorch_utils\n",
    "from preprocess import preprocessor\n",
    "from naruto_skills.training_checker import TrainingChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def docs2input_tensors(docs, device):\n",
    "    preprocessed_docs = [preprocessor.infer_preprocess(doc) for doc in docs]\n",
    "    max_len = 100\n",
    "    preprocessed_docs = [' '.join(doc.split()[:max_len]) for doc in preprocessed_docs]\n",
    "    word_input = voc.docs2idx(preprocessed_docs, equal_length=max_len)\n",
    "    inputs = np.array(word_input)\n",
    "    input_tensors = torch.from_numpy(inputs)\n",
    "    input_tensors = input_tensors.to(device)\n",
    "    return input_tensors\n",
    "\n",
    "def predict_docs(docs, batch_size):\n",
    "    return list(chain(*[predict_batch(docs[i: i+batch_size]) for i in tqdm(range(0, len(docs), batch_size))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = Voc.load('/source/main/vocab/output/voc.pkl')\n",
    "MAX_LENGTH = 100\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_model = SiameseModelCore(voc.get_embedding_weights())\n",
    "model = SiameseModel(core_model)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device('cpu')\n",
    "model = model.to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRE_TRAINED_MODEL='/source/main/train/output/saved_models/15.2/5800.pt'\n",
    "checkpoint = torch.load(PRE_TRAINED_MODEL, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch(docs):\n",
    "    return get_distance_anchors_(docs)\n",
    "\n",
    "def get_distance_anchors_(docs):\n",
    "    with torch.no_grad():\n",
    "        docs = docs2input_tensors(docs, device)\n",
    "        return model.get_distance_anchors(POS_IDX, docs).cpu().numpy().mean(axis=0)\n",
    "\n",
    "def get_distance_(doc1, doc2):\n",
    "    with torch.no_grad():\n",
    "        docs = docs2input_tensors([doc1, doc2], device)\n",
    "        return model.get_distance(docs[0:1], docs[1:]).cpu().numpy()\n",
    "    \n",
    "def get_vector(docs):\n",
    "    with torch.no_grad():\n",
    "        docs = docs2input_tensors(docs, device)\n",
    "        return model._get_inner_repr(docs).cpu().numpy()\n",
    "    \n",
    "def get_distance_from_center(docs):\n",
    "    docs = get_vector(docs)\n",
    "    return np.linalg.norm(docs-CENTER_VECTOR, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pos = pd.read_csv('/source/main/data_for_train/output/train/positive_class_1.csv')\n",
    "POS = list(df_train_pos['mention'].sample(10))\n",
    "POS_IDX = docs2input_tensors(POS, device)\n",
    "# CENTER_VECTOR = get_vector(POS).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [00:05<00:00, 16.14it/s]\n"
     ]
    }
   ],
   "source": [
    "df_train_pos['pred'] = predict_docs(list(df_train_pos['mention']), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2582.000000\n",
       "mean     19.617797  \n",
       "std      13.308473  \n",
       "min      14.338962  \n",
       "25%      14.893758  \n",
       "50%      16.252757  \n",
       "75%      19.226352  \n",
       "max      209.486053 \n",
       "Name: pred, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_pos['pred'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD=df_train_pos['pred'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos_eval = pd.read_csv('/source/main/data_for_train/output/eval/positive_class_1.csv')\n",
    "df_pos_eval = df_pos_eval.drop_duplicates(subset=['mention'])\n",
    "df_pos_eval.dropna(subset=['mention'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 17.16it/s]\n"
     ]
    }
   ],
   "source": [
    "df_pos_eval['pred'] = predict_docs(list(df_pos_eval['mention']), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7492163009404389"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_pos_eval['pred']<=THRESHOLD).sum()/df_pos_eval.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos_test = pd.read_csv('/source/main/data_for_train/output/test/positive_class_1.csv')\n",
    "df_pos_test = df_pos_test.drop_duplicates(subset=['mention'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 15.20it/s]\n"
     ]
    }
   ],
   "source": [
    "df_pos_test['pred'] = predict_docs(list(df_pos_test['mention']), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "(321, 4)\n"
     ]
    }
   ],
   "source": [
    "print(sum(df_pos_test['pred']<=THRESHOLD)/df_pos_test.shape[0])\n",
    "print(df_pos_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score: pr/P(y=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pool_test = pd.read_csv('/source/main/data_for_train/output/test/pool.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [03:23<00:00, 15.39it/s]\n"
     ]
    }
   ],
   "source": [
    "df_pool_test['pred'] = predict_docs(list(df_pool_test['mention']), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00535\n",
      "(100000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(sum(df_pool_test['pred']<=THRESHOLD)/df_pool_test.shape[0])\n",
    "print(df_pool_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention_type</th>\n",
       "      <th>mention</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19898</th>\n",
       "      <td>2</td>\n",
       "      <td>size nb cho bé mấy kg vậy . báo giá mình nhé</td>\n",
       "      <td>14.470140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3547</th>\n",
       "      <td>2</td>\n",
       "      <td>loai tu nay bn tien vay</td>\n",
       "      <td>16.551823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90723</th>\n",
       "      <td>2</td>\n",
       "      <td>bn v c</td>\n",
       "      <td>15.995890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80851</th>\n",
       "      <td>2</td>\n",
       "      <td>giá nhiu</td>\n",
       "      <td>15.191274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57635</th>\n",
       "      <td>2</td>\n",
       "      <td>giá nhiêu __d__ bịch ạ</td>\n",
       "      <td>15.047525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57827</th>\n",
       "      <td>2</td>\n",
       "      <td>gửi cho xin báo giá nhé</td>\n",
       "      <td>14.503909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84429</th>\n",
       "      <td>2</td>\n",
       "      <td>bobby xxl quần bn b</td>\n",
       "      <td>18.622555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83285</th>\n",
       "      <td>2</td>\n",
       "      <td>máy giặt panasonic __d__kg giá nhiêu bạn</td>\n",
       "      <td>15.723895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21550</th>\n",
       "      <td>2</td>\n",
       "      <td>lon friso __d__g đó nay có giá nhiêu chị ơi</td>\n",
       "      <td>16.722418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3668</th>\n",
       "      <td>2</td>\n",
       "      <td>abbott grow __d__ có giá bao nhiêu à .</td>\n",
       "      <td>14.384077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78649</th>\n",
       "      <td>2</td>\n",
       "      <td>sữa meji __d__-__d__ đợt này có giảm giá ko shop</td>\n",
       "      <td>16.913954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4223</th>\n",
       "      <td>2</td>\n",
       "      <td>giá ipx là qte hay lock đấy shop ?</td>\n",
       "      <td>16.429989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10737</th>\n",
       "      <td>2</td>\n",
       "      <td>c mua nhà tâm bao nhiêu tiền..hướng gi e tim cho</td>\n",
       "      <td>15.505054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54964</th>\n",
       "      <td>2</td>\n",
       "      <td>boa nhiêu __d__ chai ak</td>\n",
       "      <td>19.508924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31988</th>\n",
       "      <td>2</td>\n",
       "      <td>c ơi bn một hộp ạ</td>\n",
       "      <td>15.272318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98859</th>\n",
       "      <td>2</td>\n",
       "      <td>hehe ... tèn thương bn mua cho bn con đi , đứa con có bn có bè</td>\n",
       "      <td>15.729612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95768</th>\n",
       "      <td>2</td>\n",
       "      <td>giá bộ đó cho wave nhiêu a</td>\n",
       "      <td>15.987932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82567</th>\n",
       "      <td>2</td>\n",
       "      <td>bao nhiu chi</td>\n",
       "      <td>17.643793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56701</th>\n",
       "      <td>2</td>\n",
       "      <td>giá synflorix bn vậy</td>\n",
       "      <td>16.446272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8034</th>\n",
       "      <td>2</td>\n",
       "      <td>uyên sa giá nhiu ah</td>\n",
       "      <td>14.725682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mention_type  \\\n",
       "19898  2              \n",
       "3547   2              \n",
       "90723  2              \n",
       "80851  2              \n",
       "57635  2              \n",
       "57827  2              \n",
       "84429  2              \n",
       "83285  2              \n",
       "21550  2              \n",
       "3668   2              \n",
       "78649  2              \n",
       "4223   2              \n",
       "10737  2              \n",
       "54964  2              \n",
       "31988  2              \n",
       "98859  2              \n",
       "95768  2              \n",
       "82567  2              \n",
       "56701  2              \n",
       "8034   2              \n",
       "\n",
       "                                                              mention  \\\n",
       "19898  size nb cho bé mấy kg vậy . báo giá mình nhé                     \n",
       "3547   loai tu nay bn tien vay                                          \n",
       "90723  bn v c                                                           \n",
       "80851  giá nhiu                                                         \n",
       "57635  giá nhiêu __d__ bịch ạ                                           \n",
       "57827  gửi cho xin báo giá nhé                                          \n",
       "84429  bobby xxl quần bn b                                              \n",
       "83285  máy giặt panasonic __d__kg giá nhiêu bạn                         \n",
       "21550  lon friso __d__g đó nay có giá nhiêu chị ơi                      \n",
       "3668   abbott grow __d__ có giá bao nhiêu à .                           \n",
       "78649  sữa meji __d__-__d__ đợt này có giảm giá ko shop                 \n",
       "4223   giá ipx là qte hay lock đấy shop ?                               \n",
       "10737  c mua nhà tâm bao nhiêu tiền..hướng gi e tim cho                 \n",
       "54964  boa nhiêu __d__ chai ak                                          \n",
       "31988  c ơi bn một hộp ạ                                                \n",
       "98859  hehe ... tèn thương bn mua cho bn con đi , đứa con có bn có bè   \n",
       "95768  giá bộ đó cho wave nhiêu a                                       \n",
       "82567  bao nhiu chi                                                     \n",
       "56701  giá synflorix bn vậy                                             \n",
       "8034   uyên sa giá nhiu ah                                              \n",
       "\n",
       "            pred  \n",
       "19898  14.470140  \n",
       "3547   16.551823  \n",
       "90723  15.995890  \n",
       "80851  15.191274  \n",
       "57635  15.047525  \n",
       "57827  14.503909  \n",
       "84429  18.622555  \n",
       "83285  15.723895  \n",
       "21550  16.722418  \n",
       "3668   14.384077  \n",
       "78649  16.913954  \n",
       "4223   16.429989  \n",
       "10737  15.505054  \n",
       "54964  19.508924  \n",
       "31988  15.272318  \n",
       "98859  15.729612  \n",
       "95768  15.987932  \n",
       "82567  17.643793  \n",
       "56701  16.446272  \n",
       "8034   14.725682  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pool_test[df_pool_test['pred']<=THRESHOLD].sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
